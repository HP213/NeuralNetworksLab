{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sigmoid activation\n",
    "def sigmoid(input):\n",
    "    return 1/(1 + np.exp(-input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def d_sigmoid(d_init, out):\n",
    "    sig = sigmoid(out)\n",
    "    return d_init * sig * (1 - sig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init(layers=[4, 5, 2]):\n",
    "    np.random.seed(42)\n",
    "\n",
    "    params_w = {}\n",
    "    params_b = {}\n",
    "\n",
    "    for index in range(len(layers)-1):\n",
    "\n",
    "        layer_num = index + 1\n",
    "        in_layer_size = layers[index]\n",
    "        out_layer_size = layers[index + 1]\n",
    "\n",
    "        params_w['weight' + str(layer_num)] = np.random.randn(out_layer_size, in_layer_size) * 0.1\n",
    "        params_b['bias' + str(layer_num)] = np.random.randn(out_layer_size, 1) * 0.1\n",
    "\n",
    "    return params_w, params_b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_layer_forward_pass(input_activations, weights, bias):\n",
    "    print(weights)\n",
    "    y = np.transpose(weights)\n",
    "    new_bias = np.transpose(bias)\n",
    "#     y = weights\n",
    "#     print(y.shape())\n",
    "    print(y)\n",
    "    \n",
    "    output = np.dot(input_activations, y) + new_bias\n",
    "#     output = np.array([]) \n",
    "#     print(output)\n",
    "    \n",
    "    activation_next = sigmoid(output)\n",
    "    \n",
    "    return activation_next, output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_pass(train_X, params_w, params_b, layers=[4, 5, 2]):\n",
    "\n",
    "    num_layers = len(layers) - 1\n",
    "\n",
    "    activation_dict = {}\n",
    "    output_dict = {}\n",
    "\n",
    "    curr_act = train_X\n",
    "\n",
    "    for index in range(num_layers):\n",
    "#         index = 0\n",
    "        layer_index = index + 1\n",
    "        prev_act = curr_act     \n",
    "\n",
    "        curr_weight = params_w[\"weight\" + str(layer_index)]\n",
    "        curr_bias = params_b[\"bias\" + str(layer_index)]\n",
    "\n",
    "        curr_act, curr_out = one_layer_forward_pass(prev_act, curr_weight, curr_bias)\n",
    "\n",
    "        activation_dict[\"act\" + str(index)] = prev_act\n",
    "        output_dict[\"out\" + str(layer_index)] = curr_out\n",
    "#         return curr_act, activation_dict, output_dict\n",
    "    \n",
    "    return curr_act, activation_dict, output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val_split(X, Y, train_percent=0.8):\n",
    "\n",
    "    num_points = X.shape[0]\n",
    "\n",
    "    train_size = int(num_points * 100 * train_percent // 100)\n",
    "\n",
    "    inds = np.arange(num_points)\n",
    "    np.random.shuffle(inds)\n",
    "\n",
    "    train_inds = inds[:train_size]\n",
    "    val_inds = inds[train_size: ]\n",
    "\n",
    "    train_X = X[train_inds, :]\n",
    "    val_X = X[val_inds, :]\n",
    "\n",
    "    train_Y = Y[train_inds]\n",
    "    val_Y = Y[val_inds]\n",
    "\n",
    "    return train_X, train_Y, val_X, val_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_txt(fname, num_features=4, num_targets=1, num_points=1372):\n",
    "    \n",
    "    X = np.empty((num_points, num_features), dtype=float)\n",
    "    Y = np.empty(num_points, dtype=int)\n",
    "\n",
    "    with open(fname) as f:\n",
    "        for index, line in enumerate(f):\n",
    "            line = line.rstrip('\\n')\n",
    "            data = line.split(',')\n",
    "\n",
    "\n",
    "            X[index, :] = np.asarray(data[:-1])\n",
    "            Y[index] = np.asarray(data[num_features])\n",
    "\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "lr = 0.1\n",
    "\n",
    "X, Y = parse_txt('data/data.txt')\n",
    "train_X, train_Y, val_X, val_Y = train_val_split(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bias1': array([[ 0.14656488],\n",
       "        [-0.02257763],\n",
       "        [ 0.00675282],\n",
       "        [-0.14247482],\n",
       "        [-0.05443827]]), 'bias2': array([[-0.12208436],\n",
       "        [ 0.02088636]])}"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layers=[4, 5, 2]\n",
    "params_w, params_b = init(layers)\n",
    "params_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.04967142 -0.01382643  0.06476885  0.15230299]\n",
      " [-0.02341534 -0.0234137   0.15792128  0.07674347]\n",
      " [-0.04694744  0.054256   -0.04634177 -0.04657298]\n",
      " [ 0.02419623 -0.19132802 -0.17249178 -0.05622875]\n",
      " [-0.10128311  0.03142473 -0.09080241 -0.14123037]]\n",
      "[[ 0.04967142 -0.02341534 -0.04694744  0.02419623 -0.10128311]\n",
      " [-0.01382643 -0.0234137   0.054256   -0.19132802  0.03142473]\n",
      " [ 0.06476885  0.15792128 -0.04634177 -0.17249178 -0.09080241]\n",
      " [ 0.15230299  0.07674347 -0.04657298 -0.05622875 -0.14123037]]\n",
      "[[ 0.01109226 -0.11509936  0.0375698  -0.06006387 -0.02916937]\n",
      " [-0.06017066  0.18522782 -0.00134972 -0.10577109  0.08225449]]\n",
      "[[ 0.01109226 -0.06017066]\n",
      " [-0.11509936  0.18522782]\n",
      " [ 0.0375698  -0.00134972]\n",
      " [-0.06006387 -0.10577109]\n",
      " [-0.02916937  0.08225449]]\n"
     ]
    }
   ],
   "source": [
    "y_pred, activations, outputs = forward_pass(train_X, params_w, params_b, layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'out1': array([[-0.41162856, -0.60688148,  0.52881383, -0.93400855,  0.62108388],\n",
       "        [-1.12742848, -0.73861961,  1.02493951, -2.1282359 ,  1.41397605],\n",
       "        [ 0.73337783,  0.33477858, -0.3007042 , -0.63949732, -0.84010936],\n",
       "        ...,\n",
       "        [-0.29795143, -0.62849651,  0.63496518, -1.64981754,  0.52474738],\n",
       "        [ 0.11876579, -0.00660879,  0.01888744, -0.1281374 , -0.01079464],\n",
       "        [-0.18150692, -0.64068089,  0.54361099, -1.31256102,  0.40377109]]),\n",
       " 'out2': array([[-0.17054681,  0.08506513],\n",
       "        [-0.15878761,  0.1199711 ],\n",
       "        [-0.19524187,  0.07590903],\n",
       "        ...,\n",
       "        [-0.16084392,  0.09343343],\n",
       "        [-0.19722292,  0.07204662],\n",
       "        [-0.16321834,  0.08348033]])}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
